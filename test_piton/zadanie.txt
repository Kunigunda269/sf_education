# Python Test Task

Hey! Feel free to complete this short task to make us sure that you are really interested in working with us. Share your result with [Viktoria via Tg](https://t.me/vikkie_wonder).

<aside>
ğŸ‘‰ğŸ¼

Deadlines: 2 working days from the moment of receiving the test task.

</aside>

Link to job description

[Python developer for AI](https://www.notion.so/Python-developer-for-AI-1a7203040a3580ecbf15d1753c537762?pvs=21) 

## What to build

1. **Stateless chat graph** â€” the bot replies to each user message.
2. **Agent using tool** `get_current_time` that the LLM calls when the user asks for the time. E.g:
    
    ```python
    def get_current_time() -> dict:
        """Return the current UTC time in ISOâ€‘8601 format.
        Example â†’ {"utc": "2025â€‘05â€‘21T06:42:00Z"}"""
    
    ```
    
3. **Launch** with `langgraph dev`.
4. **Minimal repo** â€” a single Python file, `requirements.txt`, and a short README.

### Constraints

- Any model is fine (GPT, Gemini, DeepSeek, Ollama with local models, â€¦).
- If you depend on **Ollama** or other local runners, include exact setup commands (`ollama pull â€¦`, default port, etc.).
- No memory or databases. Exactly **one** tool (`get_current_time`).
- Hard timeâ€‘box: up to 90 â€¯minutes â€” push whatever runs.

### How weâ€™ll run it

```bash
git clone <your_repo>
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
langgraph dev
```

If during multi-turn conversation asking **â€œWhat time is it?â€** triggers the tool and returns the correct time, you pass ğŸŒÂ and we can proceed to the next part (interview).